# ğŸ­ Complete Emotion Detection & MOOD Filter System

## ğŸŒŸ Overview

This is a comprehensive emotion detection and artistic transformation system that combines:

1. **ğŸ­ Real-time Emotion Detection** - Uses DeepFace and OpenCV to detect emotions from camera feed
2. **ğŸ¨ AnimeGAN MOOD Filter** - Transforms captured images into stunning anime-style artwork using AnimeGANv2
3. **ğŸŒ Web Interface** - Beautiful Flask-based web application with multiple interfaces
4. **ğŸ“Š Analytics Dashboard** - Track and analyze emotion patterns over time

## ğŸš€ Features

### Emotion Detection System
- âœ… Real-time emotion detection using webcam
- âœ… Supports 7 emotions: Happy, Sad, Angry, Surprised, Neutral, Fear, Disgust
- âœ… High-confidence filtering (>25% confidence threshold)
- âœ… SQLite database storage with session tracking
- âœ… Beautiful Ghibli-style emotion visualization
- âœ… 10-second capture sessions with countdown

### MOOD Filter (AnimeGAN Transformations)
- âœ… **Hayao Style** - Miyazaki-inspired warm, natural anime aesthetic
- âœ… **Shinkai Style** - Vibrant, cinematic anime transformations
- âœ… **Paprika Style** - Psychedelic, dream-like artistic effects
- âœ… Real-time camera capture with preview
- âœ… High-quality image processing and saving
- âœ… Fallback to simulated filters if TensorFlow unavailable

### Web Interface
- âœ… **Main Chat Interface** - Emotion detection with chatbot interaction
- âœ… **MOOD Filter Page** - Dedicated AnimeGAN transformation interface
- âœ… **Analytics Dashboard** - Emotion statistics and data visualization
- âœ… **Responsive Design** - Works on desktop and mobile devices

## ğŸ“‹ Requirements

### System Requirements
- Python 3.7+ 
- Webcam/Camera
- 4GB+ RAM recommended
- Windows, macOS, or Linux

### Python Dependencies
```
Flask==2.3.3
opencv-python==4.8.1.78
deepface==0.0.79
numpy==1.24.3
tensorflow==2.13.0
Pillow>=9.0.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
tqdm>=4.62.0
```

## ğŸ› ï¸ Installation

### 1. Clone/Download the Repository
```bash
cd /path/to/emotion_web
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Test the System
```bash
python test_complete_system.py
```

### 4. Start the Application
```bash
python app.py
```

### 5. Access the Web Interface
Open your browser and visit:
- **Main Interface**: http://localhost:5055/
- **MOOD Filter**: http://localhost:5055/mood-filter
- **Dashboard**: http://localhost:5055/dashboard

## ğŸ® Usage Guide

### Emotion Detection

#### Via Web Interface:
1. Go to http://localhost:5055/
2. Click the **camera button** in the chat interface
3. Allow camera access when prompted
4. Look at the camera and show different expressions for 10 seconds
5. Select your favorite emotion from the Ghibli-style gallery
6. Chat with the bot about your emotions!

#### Via Python Scripts:
```python
from emotion_detector import EmotionDetector

# Initialize detector
detector = EmotionDetector(use_database=True)

# Real-time detection for 10 seconds
results = detector.detect_emotions_realtime(duration=10)

# Single image capture
result = detector.detect_emotion_single_capture()

# Get recent emotions from database
recent = detector.get_recent_emotions(limit=20)
```

### MOOD Filter (AnimeGAN Transformations)

#### Via Web Interface:
1. Go to http://localhost:5055/mood-filter
2. **Select a style**:
   - ğŸŒ¿ **Hayao** - Warm, Studio Ghibli-inspired style
   - ğŸŒŸ **Shinkai** - Vibrant, Makoto Shinkai-inspired style  
   - ğŸ­ **Paprika** - Psychedelic, Satoshi Kon-inspired style
3. Click **"Test Selected Style"** to verify the filter works
4. Click **"Capture & Apply Filter"** to take a photo
5. Wait 5 seconds or press SPACE to capture
6. View your original vs anime-transformed image!

#### Via Python Scripts:
```python
from anime_mood_filter import AnimeGANMoodFilter

# Initialize filter with style
mood_filter = AnimeGANMoodFilter(style='Hayao')  # or 'Shinkai', 'Paprika'

# Capture and apply filter
result = mood_filter.capture_and_apply_filter()

# Apply filter to existing image
anime_image = mood_filter.apply_filter_to_existing_image('path/to/image.jpg')
```

## ğŸ“ File Structure

```
emotion_web/
â”œâ”€â”€ ğŸŒ Web Application
â”‚   â”œâ”€â”€ app.py                     # Main Flask application
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ index.html            # Main chat interface
â”‚   â”‚   â”œâ”€â”€ mood_filter.html      # MOOD filter page
â”‚   â”‚   â””â”€â”€ dashboard.html        # Analytics dashboard
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ style.css             # Main styles
â”‚       â”œâ”€â”€ images/               # Emotion visualization images
â”‚       â””â”€â”€ anime_captures/       # MOOD filter outputs
â”‚
â”œâ”€â”€ ğŸ­ Emotion Detection
â”‚   â”œâ”€â”€ emotion_detector.py       # Main emotion detection class
â”‚   â”œâ”€â”€ simple_emotion_detector.py # Fallback detector
â”‚   â”œâ”€â”€ web_emotion_detect.py     # Web integration script
â”‚   â””â”€â”€ database.py               # SQLite database management
â”‚
â”œâ”€â”€ ğŸ¨ MOOD Filter System
â”‚   â”œâ”€â”€ anime_mood_filter.py      # Main AnimeGAN filter class
â”‚   â””â”€â”€ AnimeGANv2/              # AnimeGAN model files
â”‚       â”œâ”€â”€ checkpoint/           # Pre-trained model weights
â”‚       â”œâ”€â”€ net/                  # Neural network definitions
â”‚       â””â”€â”€ tools/                # Utility functions
â”‚
â”œâ”€â”€ ğŸ§ª Testing & Documentation
â”‚   â”œâ”€â”€ test_complete_system.py   # Comprehensive system test
â”‚   â”œâ”€â”€ README_COMPLETE_SYSTEM.md # This file
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”‚
â””â”€â”€ ğŸ® GUI Applications
    â”œâ”€â”€ emotion_chatbot_gui.py     # Standalone GUI application
    â”œâ”€â”€ integrated_emotion_gui.py  # GUI with web integration
    â””â”€â”€ run_emotion_chatbot.py     # Simple launcher
```

## ğŸ¨ MOOD Filter Styles

### ğŸŒ¿ Hayao Style
- **Inspiration**: Studio Ghibli films (My Neighbor Totoro, Spirited Away)
- **Characteristics**: Warm colors, soft edges, natural lighting
- **Best for**: Portraits, nature scenes, friendly expressions

### ğŸŒŸ Shinkai Style  
- **Inspiration**: Makoto Shinkai films (Your Name, Weathering with You)
- **Characteristics**: Vibrant colors, dramatic lighting, cinematic feel
- **Best for**: Landscapes, dramatic portraits, urban scenes

### ğŸ­ Paprika Style
- **Inspiration**: Satoshi Kon's Paprika
- **Characteristics**: Psychedelic colors, dream-like effects, surreal atmosphere
- **Best for**: Creative portraits, artistic expression, experimental photos

## ğŸ”§ Advanced Configuration

### Camera Settings
```python
# In emotion_detector.py and anime_mood_filter.py
self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)   # Camera resolution
self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
self.cap.set(cv2.CAP_PROP_FPS, 30)             # Frame rate
```

### Emotion Detection Tuning
```python
# In web_emotion_detect.py
confidence_threshold = 25  # Minimum confidence percentage
detection_duration = 10    # Detection time in seconds
```

### MOOD Filter Quality
```python
# In anime_mood_filter.py
self.img_size = [512, 512]  # Processing resolution (higher = better quality)
self.adjust_brightness = True  # Auto-adjust brightness to match original
```

## ğŸš¨ Troubleshooting

### Common Issues

#### 1. Camera Not Working
```bash
# Test camera access
python test_camera.py

# Check available cameras
python -c "import cv2; print([i for i in range(5) if cv2.VideoCapture(i).isOpened()])"
```

#### 2. TensorFlow/AnimeGAN Issues
- The system automatically falls back to simulated anime filters
- For full AnimeGAN functionality, ensure:
  - TensorFlow 2.13.0 is installed
  - Model weights are in `AnimeGANv2/checkpoint/`
  - GPU drivers are updated (optional)

#### 3. DeepFace Download Issues
```bash
# Manually download DeepFace models
python -c "from deepface import DeepFace; DeepFace.analyze('test.jpg', actions=['emotion'])"
```

#### 4. Permission Errors
- Ensure camera permissions are granted in your browser
- Run with administrator privileges if needed on Windows

### Performance Optimization

#### For Better Speed:
- Reduce camera resolution in configuration
- Use CPU-only mode for AnimeGAN if GPU is slow
- Lower the emotion detection duration

#### For Better Quality:
- Increase `img_size` in MOOD filter
- Use higher camera resolution
- Ensure good lighting conditions

## ğŸ“Š Database Schema

The system uses SQLite with the following schema:

```sql
CREATE TABLE emotions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    emotion TEXT NOT NULL,
    confidence REAL NOT NULL,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    session_id TEXT,
    face_coords TEXT,
    face_image_base64 TEXT
);
```

## ğŸŒ API Endpoints

### Emotion Detection
- `GET /detect` - Run 10-second emotion detection
- `GET /api/emotions/recent?limit=10` - Get recent emotions
- `GET /api/emotions/statistics` - Get emotion statistics
- `GET /api/emotions/count` - Get total emotion records

### MOOD Filter
- `GET /api/mood-filter/test/{style}` - Test filter initialization
- `GET /api/mood-filter/capture/{style}` - Capture and apply filter

### Pages
- `GET /` - Main chat interface
- `GET /mood-filter` - MOOD filter page
- `GET /dashboard` - Analytics dashboard

## ğŸ‰ What's New in This Version

### âœ¨ Major Features Added:
1. **Complete AnimeGAN Integration** - Full MOOD filter with 3 artistic styles
2. **Fallback Anime Filters** - Works even without TensorFlow
3. **Dedicated MOOD Filter Page** - Beautiful web interface for transformations
4. **Enhanced Error Handling** - Graceful degradation and user feedback
5. **Comprehensive Testing** - Full system test suite
6. **Mobile Responsive Design** - Works on all devices

### ğŸ”§ Technical Improvements:
- Modular architecture with clear separation of concerns
- Robust error handling and fallback mechanisms  
- Optimized image processing pipeline
- Enhanced camera control and settings
- Better database integration and session management

## ğŸ¤ Contributing

To extend the system:

1. **Add New Emotion Types**: Modify emotion mappings in `emotion_detector.py`
2. **Create New Anime Styles**: Add style configurations in `anime_mood_filter.py`
3. **Enhance Web Interface**: Modify templates and add new routes in `app.py`
4. **Improve Models**: Train custom emotion or style transfer models

## ğŸ“„ License

This project combines multiple technologies:
- Emotion detection: Uses DeepFace (MIT License)
- Style transfer: Uses AnimeGANv2 (See AnimeGANv2 license)
- Web framework: Uses Flask (BSD License)

## ğŸ™ Acknowledgments

- **DeepFace** team for emotion detection capabilities
- **AnimeGANv2** developers for style transfer technology
- **OpenCV** community for computer vision tools
- **Flask** team for the web framework

---

## ğŸ¯ Quick Start Summary

1. **Install**: `pip install -r requirements.txt`
2. **Test**: `python test_complete_system.py`
3. **Run**: `python app.py`
4. **Visit**: http://localhost:5055/

### For Emotion Detection:
- Click camera button in chat â†’ Show expressions for 10s â†’ Select emotion art

### For MOOD Filter:
- Go to /mood-filter â†’ Choose style â†’ Test â†’ Capture â†’ Transform!

**Enjoy your beautiful emotion detection and anime transformation system! ğŸ‰**